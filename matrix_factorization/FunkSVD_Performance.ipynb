{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Are We Doing?\n",
    "\n",
    "In the last notebook, you created a working version of SVD for situations even when there are tons of missing values.  This is awesome!  The question now is how well does this solution work?\n",
    "\n",
    "In this notebook, we are going to simulate exactly what we would do in the real world to tune our recommender.  \n",
    "\n",
    "Run the cell below to read in the data and get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('data/movies_clean.csv')\n",
    "reviews = pd.read_csv('data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the **reviews** dataframe, perform the following tasks to create a training and validation set of data we can use to test the performance of your SVD algorithm using **off-line** validation techniques.\n",
    "\n",
    " * Order the reviews dataframe from earliest to most recent \n",
    " * Pull the first 10000 reviews from  the dataset\n",
    " * Make the first 8000/10000 reviews the training data \n",
    " * Make the last 2000/10000 the test data\n",
    " * Return the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(reviews, order_by, training_size, testing_size):\n",
    "    '''    \n",
    "    INPUT:\n",
    "    reviews - (pandas df) dataframe to split into train and test\n",
    "    order_by - (string) column name to sort by\n",
    "    training_size - (int) number of rows in training set\n",
    "    testing_size - (int) number of columns in the test set\n",
    "    \n",
    "    OUTPUT:\n",
    "    training_df -  (pandas df) dataframe of the training set\n",
    "    validation_df - (pandas df) dataframe of the test set\n",
    "    '''\n",
    "    ordered_reviews = reviews.sort_values(by=order_by)\n",
    "    \n",
    "    training_df = ordered_reviews.iloc[:training_size, :]\n",
    "    validation_df = ordered_reviews.iloc[training_size:training_size+testing_size, :]\n",
    "    return training_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to change in this or the next cell\n",
    "# Use our function to create training and test datasets\n",
    "train_df, val_df = create_train_test(reviews, 'date', 8000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the dataframes we are using are the right shape\n",
    "assert train_df.shape[0] == 8000, \"The number of rows doesn't look right in the training dataset.\"\n",
    "assert val_df.shape[0] == 2000, \"The number of rows doesn't look right in the validation dataset\"\n",
    "assert str(train_df.tail(1)['date']).split()[1] == '2013-03-15', \"The last date in the training dataset doesn't look like what we expected.\"\n",
    "assert str(val_df.tail(1)['date']).split()[1] == '2013-03-18', \"The last date in the validation dataset doesn't look like what we expected.\"\n",
    "print(\"Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world, we might have all of the data up to this final date in the training data.  Then we want to see how well we are doing for each of the new ratings, which show up in the test data.\n",
    "\n",
    "Below is a working example of the function created in the previous example you can use (or you can replace with your own).\n",
    "\n",
    "`2.`  Fit the function to the training data with the following hyperparameters: 15 latent features, a learning rate of 0.005, and 250 iterations. This will take some time to run, so you may choose fewer latent features, a higher learning rate, or fewer iteratios if you want to speed up the process.  \n",
    "\n",
    "**Note:** Again, this might be a good time to take a phone call, go for a walk, or just take a little break.  No need to change the code below unless you would like to make changes to reduce the time needed to obtain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=12, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = ratings_mat.shape[0]\n",
    "    n_movies = ratings_mat.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # keep track of iteration and MSE\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if ratings_mat[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "        # print results\n",
    "        print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 10.598544\n",
      "2 \t\t 5.953297\n",
      "3 \t\t 4.144326\n",
      "4 \t\t 3.094323\n",
      "5 \t\t 2.408043\n",
      "6 \t\t 1.925133\n",
      "7 \t\t 1.568415\n",
      "8 \t\t 1.296078\n",
      "9 \t\t 1.083185\n",
      "10 \t\t 0.913754\n",
      "11 \t\t 0.776991\n",
      "12 \t\t 0.665314\n",
      "13 \t\t 0.573223\n",
      "14 \t\t 0.496624\n",
      "15 \t\t 0.432406\n",
      "16 \t\t 0.378174\n",
      "17 \t\t 0.332059\n",
      "18 \t\t 0.292600\n",
      "19 \t\t 0.258640\n",
      "20 \t\t 0.229263\n",
      "21 \t\t 0.203736\n",
      "22 \t\t 0.181465\n",
      "23 \t\t 0.161968\n",
      "24 \t\t 0.144847\n",
      "25 \t\t 0.129773\n",
      "26 \t\t 0.116470\n",
      "27 \t\t 0.104703\n",
      "28 \t\t 0.094276\n",
      "29 \t\t 0.085018\n",
      "30 \t\t 0.076783\n",
      "31 \t\t 0.069447\n",
      "32 \t\t 0.062901\n",
      "33 \t\t 0.057050\n",
      "34 \t\t 0.051812\n",
      "35 \t\t 0.047116\n",
      "36 \t\t 0.042900\n",
      "37 \t\t 0.039109\n",
      "38 \t\t 0.035695\n",
      "39 \t\t 0.032616\n",
      "40 \t\t 0.029836\n",
      "41 \t\t 0.027322\n",
      "42 \t\t 0.025046\n",
      "43 \t\t 0.022982\n",
      "44 \t\t 0.021109\n",
      "45 \t\t 0.019406\n",
      "46 \t\t 0.017857\n",
      "47 \t\t 0.016446\n",
      "48 \t\t 0.015159\n",
      "49 \t\t 0.013985\n",
      "50 \t\t 0.012911\n",
      "51 \t\t 0.011929\n",
      "52 \t\t 0.011030\n",
      "53 \t\t 0.010206\n",
      "54 \t\t 0.009450\n",
      "55 \t\t 0.008757\n",
      "56 \t\t 0.008119\n",
      "57 \t\t 0.007533\n",
      "58 \t\t 0.006993\n",
      "59 \t\t 0.006496\n",
      "60 \t\t 0.006038\n",
      "61 \t\t 0.005616\n",
      "62 \t\t 0.005226\n",
      "63 \t\t 0.004865\n",
      "64 \t\t 0.004532\n",
      "65 \t\t 0.004224\n",
      "66 \t\t 0.003939\n",
      "67 \t\t 0.003675\n",
      "68 \t\t 0.003431\n",
      "69 \t\t 0.003204\n",
      "70 \t\t 0.002993\n",
      "71 \t\t 0.002798\n",
      "72 \t\t 0.002617\n",
      "73 \t\t 0.002448\n",
      "74 \t\t 0.002291\n",
      "75 \t\t 0.002145\n",
      "76 \t\t 0.002010\n",
      "77 \t\t 0.001883\n",
      "78 \t\t 0.001765\n",
      "79 \t\t 0.001656\n",
      "80 \t\t 0.001553\n",
      "81 \t\t 0.001458\n",
      "82 \t\t 0.001369\n",
      "83 \t\t 0.001285\n",
      "84 \t\t 0.001208\n",
      "85 \t\t 0.001135\n",
      "86 \t\t 0.001067\n",
      "87 \t\t 0.001003\n",
      "88 \t\t 0.000944\n",
      "89 \t\t 0.000888\n",
      "90 \t\t 0.000836\n",
      "91 \t\t 0.000787\n",
      "92 \t\t 0.000742\n",
      "93 \t\t 0.000699\n",
      "94 \t\t 0.000658\n",
      "95 \t\t 0.000621\n",
      "96 \t\t 0.000585\n",
      "97 \t\t 0.000552\n",
      "98 \t\t 0.000521\n",
      "99 \t\t 0.000491\n",
      "100 \t\t 0.000464\n",
      "101 \t\t 0.000438\n",
      "102 \t\t 0.000414\n",
      "103 \t\t 0.000391\n",
      "104 \t\t 0.000369\n",
      "105 \t\t 0.000349\n",
      "106 \t\t 0.000330\n",
      "107 \t\t 0.000312\n",
      "108 \t\t 0.000295\n",
      "109 \t\t 0.000279\n",
      "110 \t\t 0.000264\n",
      "111 \t\t 0.000250\n",
      "112 \t\t 0.000236\n",
      "113 \t\t 0.000224\n",
      "114 \t\t 0.000212\n",
      "115 \t\t 0.000201\n",
      "116 \t\t 0.000190\n",
      "117 \t\t 0.000180\n",
      "118 \t\t 0.000171\n",
      "119 \t\t 0.000162\n",
      "120 \t\t 0.000153\n",
      "121 \t\t 0.000145\n",
      "122 \t\t 0.000138\n",
      "123 \t\t 0.000131\n",
      "124 \t\t 0.000124\n",
      "125 \t\t 0.000118\n",
      "126 \t\t 0.000112\n",
      "127 \t\t 0.000106\n",
      "128 \t\t 0.000101\n",
      "129 \t\t 0.000096\n",
      "130 \t\t 0.000091\n",
      "131 \t\t 0.000086\n",
      "132 \t\t 0.000082\n",
      "133 \t\t 0.000078\n",
      "134 \t\t 0.000074\n",
      "135 \t\t 0.000070\n",
      "136 \t\t 0.000067\n",
      "137 \t\t 0.000064\n",
      "138 \t\t 0.000061\n",
      "139 \t\t 0.000058\n",
      "140 \t\t 0.000055\n",
      "141 \t\t 0.000052\n",
      "142 \t\t 0.000050\n",
      "143 \t\t 0.000047\n",
      "144 \t\t 0.000045\n",
      "145 \t\t 0.000043\n",
      "146 \t\t 0.000041\n",
      "147 \t\t 0.000039\n",
      "148 \t\t 0.000037\n",
      "149 \t\t 0.000035\n",
      "150 \t\t 0.000034\n",
      "151 \t\t 0.000032\n",
      "152 \t\t 0.000031\n",
      "153 \t\t 0.000029\n",
      "154 \t\t 0.000028\n",
      "155 \t\t 0.000026\n",
      "156 \t\t 0.000025\n",
      "157 \t\t 0.000024\n",
      "158 \t\t 0.000023\n",
      "159 \t\t 0.000022\n",
      "160 \t\t 0.000021\n",
      "161 \t\t 0.000020\n",
      "162 \t\t 0.000019\n",
      "163 \t\t 0.000018\n",
      "164 \t\t 0.000017\n",
      "165 \t\t 0.000017\n",
      "166 \t\t 0.000016\n",
      "167 \t\t 0.000015\n",
      "168 \t\t 0.000014\n",
      "169 \t\t 0.000014\n",
      "170 \t\t 0.000013\n",
      "171 \t\t 0.000013\n",
      "172 \t\t 0.000012\n",
      "173 \t\t 0.000012\n",
      "174 \t\t 0.000011\n",
      "175 \t\t 0.000011\n",
      "176 \t\t 0.000010\n",
      "177 \t\t 0.000010\n",
      "178 \t\t 0.000009\n",
      "179 \t\t 0.000009\n",
      "180 \t\t 0.000008\n",
      "181 \t\t 0.000008\n",
      "182 \t\t 0.000008\n",
      "183 \t\t 0.000007\n",
      "184 \t\t 0.000007\n",
      "185 \t\t 0.000007\n",
      "186 \t\t 0.000006\n",
      "187 \t\t 0.000006\n",
      "188 \t\t 0.000006\n",
      "189 \t\t 0.000006\n",
      "190 \t\t 0.000005\n",
      "191 \t\t 0.000005\n",
      "192 \t\t 0.000005\n",
      "193 \t\t 0.000005\n",
      "194 \t\t 0.000005\n",
      "195 \t\t 0.000004\n",
      "196 \t\t 0.000004\n",
      "197 \t\t 0.000004\n",
      "198 \t\t 0.000004\n",
      "199 \t\t 0.000004\n",
      "200 \t\t 0.000004\n",
      "201 \t\t 0.000003\n",
      "202 \t\t 0.000003\n",
      "203 \t\t 0.000003\n",
      "204 \t\t 0.000003\n",
      "205 \t\t 0.000003\n",
      "206 \t\t 0.000003\n",
      "207 \t\t 0.000003\n",
      "208 \t\t 0.000003\n",
      "209 \t\t 0.000002\n",
      "210 \t\t 0.000002\n",
      "211 \t\t 0.000002\n",
      "212 \t\t 0.000002\n",
      "213 \t\t 0.000002\n",
      "214 \t\t 0.000002\n",
      "215 \t\t 0.000002\n",
      "216 \t\t 0.000002\n",
      "217 \t\t 0.000002\n",
      "218 \t\t 0.000002\n",
      "219 \t\t 0.000002\n",
      "220 \t\t 0.000002\n",
      "221 \t\t 0.000001\n",
      "222 \t\t 0.000001\n",
      "223 \t\t 0.000001\n",
      "224 \t\t 0.000001\n",
      "225 \t\t 0.000001\n",
      "226 \t\t 0.000001\n",
      "227 \t\t 0.000001\n",
      "228 \t\t 0.000001\n",
      "229 \t\t 0.000001\n",
      "230 \t\t 0.000001\n",
      "231 \t\t 0.000001\n",
      "232 \t\t 0.000001\n",
      "233 \t\t 0.000001\n",
      "234 \t\t 0.000001\n",
      "235 \t\t 0.000001\n",
      "236 \t\t 0.000001\n",
      "237 \t\t 0.000001\n",
      "238 \t\t 0.000001\n",
      "239 \t\t 0.000001\n",
      "240 \t\t 0.000001\n",
      "241 \t\t 0.000001\n",
      "242 \t\t 0.000001\n",
      "243 \t\t 0.000001\n",
      "244 \t\t 0.000001\n",
      "245 \t\t 0.000001\n",
      "246 \t\t 0.000001\n",
      "247 \t\t 0.000001\n",
      "248 \t\t 0.000001\n",
      "249 \t\t 0.000000\n",
      "250 \t\t 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Create user-by-item matrix - nothing to do here\n",
    "train_user_item = train_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "train_data_np = np.array(train_data_df)\n",
    "\n",
    "# Fit FunkSVD with the specified hyper parameters to the training data\n",
    "user_mat, movie_mat = FunkSVD(train_data_np, latent_features=15, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the **user_mat** and **movie_mat**, we can use this to make predictions for how users would rate movies, by just computing the dot product of the row associated with a user and the column associated with the movie.\n",
    "\n",
    "`3.` Use the comments in the function below to complete the **predict_rating** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50012684,  0.80406459,  0.61767635,  0.33846321,  0.64656298,\n",
       "        0.8049172 ,  0.94233914,  1.26710714,  0.9282181 ,  0.6250358 ,\n",
       "        0.51311048,  0.51160688,  1.1630962 ,  0.47388083,  1.19085143])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mat[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_matrix, movie_matrix, user_id, movie_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_matrix - user by latent factor matrix\n",
    "    movie_matrix - latent factor by movie matrix\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    \n",
    "    OUTPUT:\n",
    "    pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "    '''\n",
    "    # Use the training data to create a series of users and movies that matches the ordering in training data\n",
    "    row = np.where((train_data_df.index.values) == user_id)[0][0]\n",
    "    col = np.where((train_data_df.columns.values) == movie_id)[0][0]\n",
    "\n",
    "    # User row and Movie Column\n",
    "    u = user_matrix[row, :]\n",
    "    v = movie_matrix[:, col]\n",
    "    # Take dot product of that row and column in U and V to make prediction\n",
    "    pred = np.dot(u, v)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4782386720763627"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with the first user-movie in the user-movie matrix (notice this is a nan)\n",
    "pred_val = predict_rating(user_mat, movie_mat, 8, 2844)\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is great that you now have a way to make predictions. However it might be nice to get a little phrase back about the user, movie, and rating.\n",
    "\n",
    "`4.` Use the comments in the function below to complete the **predict_rating** function.  \n",
    "\n",
    "**Note:** The movie name doesn't come back in a great format, so you can see in the solution I messed around with it a bit just to make it a little nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction_summary(user_id, movie_id, prediction):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    prediction - the predicted rating for user_id-movie_id\n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints a statement about the user, movie, and prediction made\n",
    "    \n",
    "    '''\n",
    "    print('For user {} movie {}, the predicted rating is {:.0f}'.format(user_id, movie_id, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user 8 movie 2844, the predicted rating is 7\n"
     ]
    }
   ],
   "source": [
    "# Test your function the the results of the previous function\n",
    "print_prediction_summary(8, 2844, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the ability to make predictions, let's see how well our predictions do on the test ratings we already have.  This will give an indication of how well we have captured the latent features, and our ability to use the latent features to make predictions in the future!\n",
    "\n",
    "`5.` For each of the user-movie rating in the **val_df** dataset, compare the actual rating given to the prediction you would make.  How do your predictions do?  Do you run into any problems?  If yes, what is the problem?  Use the document strings and comments below to assist as you work through these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650588</th>\n",
       "      <td>49056</td>\n",
       "      <td>1598822</td>\n",
       "      <td>8</td>\n",
       "      <td>1363308721</td>\n",
       "      <td>2013-03-15 00:52:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650569</th>\n",
       "      <td>49056</td>\n",
       "      <td>289879</td>\n",
       "      <td>9</td>\n",
       "      <td>1363308742</td>\n",
       "      <td>2013-03-15 00:52:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650585</th>\n",
       "      <td>49056</td>\n",
       "      <td>1563738</td>\n",
       "      <td>9</td>\n",
       "      <td>1363308780</td>\n",
       "      <td>2013-03-15 00:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650583</th>\n",
       "      <td>49056</td>\n",
       "      <td>1458175</td>\n",
       "      <td>4</td>\n",
       "      <td>1363308799</td>\n",
       "      <td>2013-03-15 00:53:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378686</th>\n",
       "      <td>28599</td>\n",
       "      <td>103639</td>\n",
       "      <td>8</td>\n",
       "      <td>1363309112</td>\n",
       "      <td>2013-03-15 00:58:32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667660</th>\n",
       "      <td>50593</td>\n",
       "      <td>1560985</td>\n",
       "      <td>4</td>\n",
       "      <td>1363309202</td>\n",
       "      <td>2013-03-15 01:00:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385306</th>\n",
       "      <td>29000</td>\n",
       "      <td>287978</td>\n",
       "      <td>9</td>\n",
       "      <td>1363309214</td>\n",
       "      <td>2013-03-15 01:00:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
       "650588    49056   1598822       8  1363308721  2013-03-15 00:52:01        0   \n",
       "650569    49056    289879       9  1363308742  2013-03-15 00:52:22        0   \n",
       "650585    49056   1563738       9  1363308780  2013-03-15 00:53:00        0   \n",
       "650583    49056   1458175       4  1363308799  2013-03-15 00:53:19        0   \n",
       "378686    28599    103639       8  1363309112  2013-03-15 00:58:32        0   \n",
       "667660    50593   1560985       4  1363309202  2013-03-15 01:00:02        0   \n",
       "385306    29000    287978       9  1363309214  2013-03-15 01:00:14        0   \n",
       "\n",
       "        month_2  month_3  month_4  month_5    ...      month_9  month_10  \\\n",
       "650588        0        0        0        0    ...            0         0   \n",
       "650569        0        0        0        0    ...            0         0   \n",
       "650585        0        0        0        0    ...            0         0   \n",
       "650583        0        0        0        0    ...            0         0   \n",
       "378686        0        0        0        0    ...            0         0   \n",
       "667660        0        0        0        0    ...            0         0   \n",
       "385306        0        0        0        0    ...            0         0   \n",
       "\n",
       "        month_11  month_12  year_2013  year_2014  year_2015  year_2016  \\\n",
       "650588         0         0          1          0          0          0   \n",
       "650569         0         0          1          0          0          0   \n",
       "650585         0         0          1          0          0          0   \n",
       "650583         0         0          1          0          0          0   \n",
       "378686         0         0          1          0          0          0   \n",
       "667660         0         0          1          0          0          0   \n",
       "385306         0         0          1          0          0          0   \n",
       "\n",
       "        year_2017  year_2018  \n",
       "650588          0          0  \n",
       "650569          0          0  \n",
       "650585          0          0  \n",
       "650583          0          0  \n",
       "378686          0          0  \n",
       "667660          0          0  \n",
       "385306          0          0  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual rating is 8\n",
      "For user 49056 movie 1598822, the predicted rating is 6\n",
      "The actual rating is 9\n",
      "For user 49056 movie 289879, the predicted rating is 7\n",
      "The actual rating is 9\n",
      "For user 49056 movie 1563738, the predicted rating is 8\n",
      "The actual rating is 4\n",
      "For user 49056 movie 1458175, the predicted rating is 7\n",
      "The actual rating is 8\n",
      "For user 28599 movie 103639, the predicted rating is 8\n",
      "The actual rating is 4\n",
      "For user 50593 movie 1560985, the predicted rating is 3\n"
     ]
    }
   ],
   "source": [
    "def validation_comparison(val_df, num_preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    val_df - the validation dataset created in the third cell above\n",
    "    num_preds - (int) the number of rows (going in order) you would like to make predictions for\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing returned - print a statement about the prediciton made for each row of val_df from row 0 to num_preds\n",
    "    '''\n",
    "    for i in range(num_preds):\n",
    "        user_id = val_df['user_id'].iloc[i]\n",
    "        movie_id = val_df['movie_id'].iloc[i]\n",
    "        actual_rating = val_df['rating'].iloc[i]\n",
    "        print('The actual rating is {}'.format(actual_rating))\n",
    "        pred_val = predict_rating(user_mat, movie_mat, user_id, movie_id)\n",
    "        print_prediction_summary(user_id, movie_id, pred_val)\n",
    "    \n",
    "# Perform the predicted vs. actual for the first 6 rows.  How does it look?\n",
    "validation_comparison(val_df, 6)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1560985 in train_data_df.columns\n",
    "np.where((train_data_df.columns.values) == 287978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual rating is 8\n",
      "For user 49056 movie 1598822, the predicted rating is 6\n",
      "The actual rating is 9\n",
      "For user 49056 movie 289879, the predicted rating is 7\n",
      "The actual rating is 9\n",
      "For user 49056 movie 1563738, the predicted rating is 8\n",
      "The actual rating is 4\n",
      "For user 49056 movie 1458175, the predicted rating is 7\n",
      "The actual rating is 8\n",
      "For user 28599 movie 103639, the predicted rating is 8\n",
      "The actual rating is 4\n",
      "For user 50593 movie 1560985, the predicted rating is 3\n",
      "The actual rating is 9\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-70188ffbf3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform the predicted vs. actual for the first 7 rows.  What happened?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidation_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-7e1f8d0b6aef>\u001b[0m in \u001b[0;36mvalidation_comparison\u001b[0;34m(val_df, num_preds)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mactual_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The actual rating is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_rating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint_prediction_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-1a1be037a302>\u001b[0m in \u001b[0;36mpredict_rating\u001b[0;34m(user_matrix, movie_matrix, user_id, movie_id)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Use the training data to create a series of users and movies that matches the ordering in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# User row and Movie Column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Perform the predicted vs. actual for the first 7 rows.  What happened?\n",
    "validation_comparison(val_df, 7)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A statement about why you think what happened happened.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "287978 in train_data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the training data, no user have ever watched movie 287978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
